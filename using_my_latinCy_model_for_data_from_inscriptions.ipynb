{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- unzip the inscription-model folder as folder `model-best`\n",
        "- have CSV with text column in Leiden format\n",
        "- run this script"
      ],
      "metadata": {
        "id": "B8GLWsmU2pXD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24Q_3hZl2lyR"
      },
      "outputs": [],
      "source": [
        "# CELL 1: Copy model to Colab\n",
        "from google.colab import files\n",
        "files.upload()  # Upload model-best/ folder\n",
        "\n",
        "# CELL 2: Upload inscriptions\n",
        "files.upload()  # Upload inscriptions.csv\n",
        "\n",
        "# CELL 3: Run inference\n",
        "import csv\n",
        "import re\n",
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "class LeidenProcessor:\n",
        "    \"\"\"Convert Leiden conventions to clean transcription\"\"\"\n",
        "\n",
        "    # Map abbreviations to their expansions\n",
        "    # Capitalize proper nouns, keep others lowercase\n",
        "    ABBREV_PROPER = {  # Names (capitalize)\n",
        "        'Q': 'Quintus', 'C': 'Caius', 'M': 'Marcus', 'L': 'Lucius',\n",
        "        'T': 'Titus', 'P': 'Publius', 'D': 'Dis', 'A': 'Aulus',\n",
        "        'Cn': 'Gnaeus', 'TI': 'Tiberius', 'S': 'Sextus', 'N': 'Numerius',\n",
        "    }\n",
        "\n",
        "    ABBREV_COMMON = {  # Common words (lowercase)\n",
        "        'a': 'animo', 'l': 'libens', 'v': 'votum', 'p': 'posuit',\n",
        "        's': 'sacrum', 'f': 'fecit', 'm': 'mensis', 'an': 'anno',\n",
        "        'ann': 'annorum', 'h': 'hic', 'e': 'est', 'pos': 'posuit',\n",
        "        't': 'tibi', 'd': 'de', 'sit': 'sit'\n",
        "    }\n",
        "\n",
        "    @staticmethod\n",
        "    def process(leiden_text):\n",
        "        \"\"\"Full pipeline: Leiden → clean transcription\"\"\"\n",
        "\n",
        "        # Step 1: Remove damage markers [3] (n unknown letters)\n",
        "        text = re.sub(r'\\[\\d+\\]', '', leiden_text)\n",
        "\n",
        "        # Step 2: Remove question marks and uncertain markers\n",
        "        text = re.sub(r'\\?', '', text)\n",
        "        text = re.sub(r'\\[([^\\]]*)\\]', r'\\1', text)  # [text] → text\n",
        "\n",
        "        # Step 3: Join words broken across lines intelligently\n",
        "        # Handle patterns like \"Gem/ellian\" or \"ann]or/um\"\n",
        "        # Remove line breaks only when joining word fragments\n",
        "        text = re.sub(r'([a-z])/([a-z])', r'\\1\\2', text, flags=re.IGNORECASE)\n",
        "        text = re.sub(r'(\\])/([a-z])', r'\\1\\2', text, flags=re.IGNORECASE)\n",
        "\n",
        "        # Step 4: Expand abbreviations with proper case handling\n",
        "        def expand_abbrev(match):\n",
        "            abbrev = match.group(1)\n",
        "            expansion = match.group(2) if match.group(2) else \"\"\n",
        "\n",
        "            # If expansion provided in parentheses, use it\n",
        "            if expansion:\n",
        "                # Keep expansion as-is, preserve case\n",
        "                return abbrev + expansion\n",
        "\n",
        "            # Try proper noun abbreviations first\n",
        "            if abbrev in LeidenProcessor.ABBREV_PROPER:\n",
        "                return LeidenProcessor.ABBREV_PROPER[abbrev]\n",
        "\n",
        "            # Try common abbreviations\n",
        "            if abbrev.lower() in LeidenProcessor.ABBREV_COMMON:\n",
        "                return LeidenProcessor.ABBREV_COMMON[abbrev.lower()]\n",
        "\n",
        "            # Return original if not found\n",
        "            return abbrev\n",
        "\n",
        "        # Pattern: X(expansion) captures abbreviation and optional expansion text\n",
        "        text = re.sub(r'([A-Za-z]+)\\(([^)]*)\\)', expand_abbrev, text)\n",
        "\n",
        "        # Step 5: Clean line break markers and multiple spaces\n",
        "        text = text.replace('/', ' ')\n",
        "        text = text.replace('\\\\', ' ')\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        # Step 6: Remove remaining brackets and junk\n",
        "        text = re.sub(r'[\\[\\]]', '', text)\n",
        "\n",
        "        # Step 7: Capitalize only first letter and proper nouns\n",
        "        # Simple heuristic: capitalize after space, but preserve lowercase articles/prepositions\n",
        "        LOWERCASE_WORDS = {'et', 'de', 'a', 'in', 'ex', 'ab'}\n",
        "\n",
        "        words = text.split()\n",
        "        result = []\n",
        "\n",
        "        for i, word in enumerate(words):\n",
        "            if i == 0:  # First word always capitalized\n",
        "                result.append(word.capitalize())\n",
        "            elif word.lower() in LOWERCASE_WORDS:\n",
        "                result.append(word.lower())\n",
        "            elif word[0].isupper():  # Already capitalized (likely a name)\n",
        "                result.append(word)\n",
        "            else:\n",
        "                result.append(word.capitalize())\n",
        "\n",
        "        return ' '.join(result)\n",
        "\n",
        "# Load model\n",
        "nlp = spacy.load(\"model-best\")\n",
        "\n",
        "# Process CSV\n",
        "predictions = []\n",
        "with open('inscriptions.csv', 'r', encoding='utf-8') as f:\n",
        "    for i, row in enumerate(csv.DictReader(f), 1):\n",
        "        leiden = row['text'].strip()\n",
        "        trans = LeidenProcessor.process(leiden)\n",
        "        doc = nlp(trans)\n",
        "\n",
        "        entities = [{\"text\": ent.text, \"label\": ent.label_} for ent in doc.ents]\n",
        "        predictions.append({\"leiden\": leiden, \"text\": trans, \"entities\": entities})\n",
        "\n",
        "# Export\n",
        "df = pd.DataFrame([\n",
        "    {\"leiden\": p[\"leiden\"], \"transcription\": p[\"text\"],\n",
        "     \"entities\": \" | \".join([f\"{e['text']} ({e['label']})\" for e in p[\"entities\"]])}\n",
        "    for p in predictions\n",
        "])\n",
        "\n",
        "df.to_csv(\"predictions.csv\", index=False)\n",
        "files.download(\"predictions.csv\")\n",
        "\n",
        "print(f\"✅ Processed {len(predictions)} inscriptions\")\n",
        "print(df.head())"
      ]
    }
  ]
}